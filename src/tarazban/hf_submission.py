import os, uuid, json
from datetime import datetime
import pytz
import pandas as pd
from datasets import load_dataset, Dataset
from huggingface_hub import HfApi
from huggingface_hub.utils import HfHubHTTPError


HF_TOKEN = os.environ.get("HF_TOKEN")
DATASET_NAME = "ailabs-itrc/requests"   # ÛŒØ§ your-username/requests

def ensure_private_dataset(repo_id: str, token: str):
    """
    Ø§Ú¯Ø± Ø¯ÛŒØªØ§Ø³Øª ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ØŒ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Private Ù…ÛŒâ€ŒØ³Ø§Ø²Ø¯.
    Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ú©Ø§Ø±ÛŒ Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    api = HfApi(token=token)
    try:
        # Ø§Ú¯Ø± Ù†Ø¨ÙˆØ¯ØŒ Ø¨Ø³Ø§Ø²
        api.create_repo(
            repo_id=repo_id,          # Ù…Ø«Ø§Ù„: "ailabs-itrc/requests"
            repo_type="dataset",
            private=True,             # Ù…Ù‡Ù…: Ù¾Ø±Ø§ÛŒÙˆØª
            exist_ok=True
        )
    except HfHubHTTPError as e:
        # Ø§Ú¯Ø± 403 Ú¯Ø±ÙØªÛŒ ÛŒØ¹Ù†ÛŒ ØªÙˆÚ©Ù† Ø¯Ø³ØªØ±Ø³ÛŒ Ø³Ø§Ø®Øª Ø²ÛŒØ± org Ø±Ø§ Ù†Ø¯Ø§Ø±Ø¯
        raise RuntimeError(
            f"Cannot create dataset '{repo_id}'. "
            f"Check Org Write permission for this token. Original: {e}"
        )

def submit_request(
    model_name, revision, precision, weight_type,
    model_type, params, license_str, private_bool
):
    TRIM_CHARS = ' \t\n\r"\'`.,:;!ØŸØŒØ›â€¦Â«Â»()[]{}|/\\'
    
    model_name = model_name.strip(TRIM_CHARS)
    try:
        # if not HF_TOKEN:
        #     return "âŒ Error: Secret HF_TOKEN not found in Space."

        # # 1) Ù…Ø·Ù…Ø¦Ù† Ø´Ùˆ Ø¯ÛŒØªØ§Ø³Øª ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ (Ùˆ Ù¾Ø±Ø§ÛŒÙˆØª Ø§Ø³Øª)
        # ensure_private_dataset(DATASET_NAME, HF_TOKEN)
        api = HfApi(token=HF_TOKEN)

#         # ğŸ” Ø§ÙˆÙ„: Ú†Ú© Ú©Ù† Ù…Ø¯Ù„ Ø±ÙˆÛŒ Hub ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù‡ ÛŒØ§ Ù†Ù‡
        try:
            api.model_info(model_name)  # Ø§Ú¯Ø± Ù†Ø¨ÙˆØ¯ØŒ Ø®Ø·Ø§ Ù…ÛŒØ¯Ù‡
        except HfHubHTTPError as e:
            code = e.response.status_code if getattr(e, "response", None) else "?"
            # if code == 404:
            return f"âŒ Error: Model '{model_name}' not found on Hugging Face Hub."
            # return f"âŒ Error while checking model on Hub: {e}"
        # 2) Ø¯ÛŒØªØ§Ø³Øª Ø±Ø§ Ø¨Ø®ÙˆØ§Ù† (Ø§Ú¯Ø± Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯ØŒ Ø§Ø² Ù„ÛŒØ³Øª Ø®Ø§Ù„ÛŒ Ø´Ø±ÙˆØ¹ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…)
        try:
            dataset = load_dataset(DATASET_NAME, split="train", token=HF_TOKEN)
        except Exception:
            dataset = Dataset.from_list([])  # Ø¯ÛŒØªØ§Ø³Øª Ø¬Ø¯ÛŒØ¯/Ø®Ø§Ù„ÛŒ

        # 3) Ú†Ú© ØªÚ©Ø±Ø§Ø±ÛŒ Ù†Ø¨ÙˆØ¯Ù†
        existing_models = [entry.get("model") for entry in dataset]
        if model_name in existing_models:
            return f"âš ï¸ Model '{model_name}' already exists."

        # 4) Ø±Ú©ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯
        tehran = pytz.timezone("Asia/Tehran")
        now = datetime.now(tehran).strftime("%Y-%m-%dT%H:%M:%S")

        new_entry = {
            "id": str(uuid.uuid4()),
            "model": model_name,
            "revision": revision,
            "precision": precision,
            "weight_type": weight_type,
            "submitted_time": now,
            "model_type": model_type,
            "params": float(params) if (params not in [None, ""]) else None,
            "license": license_str,
            "private": bool(private_bool),
            "status": "â³ pending"
        }

        dataset = dataset.add_item(new_entry)

        # 5) Ù¾ÙˆØ´ Ø¨Ù‡ Ù‡Ø§Ø¨
        dataset.push_to_hub(DATASET_NAME, token=HF_TOKEN)

        return f"âœ… Submitted! ID: {new_entry['id']}"
    except HfHubHTTPError as e:
        # Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù‡Ø§Ø¨ Ø±Ø§ Ø®ÙˆØ§Ù†Ø§ØªØ± Ú©Ù†
        return (
            "âŒ Error while pushing to Hub:\n"
            f"{e}\n\n"
            "Ø±Ø§Ù‡Ù†Ù…Ø§: Ø§Ú¯Ø± 403 Ù…ÛŒâ€ŒØ¨ÛŒÙ†ÛŒØŒ ØªÙˆÚ©Ù† Ø¨Ø§ÛŒØ¯ Org Write Ø¨Ø±Ø§ÛŒ 'ailabs-itrc' Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ "
            "ÛŒØ§ DATASET_NAME Ø±Ø§ Ù…ÙˆÙ‚ØªØ§Ù‹ Ø¨Ù‡ ÙØ¶Ø§ÛŒ Ø´Ø®ØµÛŒ Ø®ÙˆØ¯Øª Ø¨Ø¨Ø±ÛŒ."
        )
    except Exception as e:
        return f"âŒ Error: {e}"
